# 7.1 Vercel AI SDK 集成

> **模型**: claude-opus-4-6 (anthropic/claude-opus-4-6)  
> **生成日期**: 2026-02-17

---

OpenCode 需要对接 20 多个 LLM Provider（Anthropic、OpenAI、Google、Azure、AWS Bedrock 等），每个 Provider 都有自己独特的 API 格式、认证方式和能力特征。如果为每个 Provider 编写独立的适配代码，维护成本将极其高昂。OpenCode 选择了 **Vercel AI SDK**（npm 包名 `ai`）作为统一的 LLM 抽象层，在此之上构建自己的适配体系。

## 7.1.1 为什么选择 Vercel AI SDK？

> **衍生解释：Vercel AI SDK 的核心概念**
>
> Vercel AI SDK 是一个由 Vercel 公司开发的开源 TypeScript 库，旨在为 LLM 应用提供统一的编程接口。它的核心概念包括：
>
> - **`streamText()`**：流式文本生成——发送消息给 LLM 并以流的形式接收回复，支持工具调用。
> - **`generateObject()`**：结构化对象生成——让 LLM 返回符合指定 Schema 的 JSON 对象。
> - **`LanguageModelV2`**：统一的语言模型接口——所有 Provider 的 SDK 都实现这个接口，使得上层代码无需关心底层 Provider 的差异。
> - **`Tool`**：工具定义——声明式地定义 LLM 可以调用的函数，包括参数 Schema 和执行逻辑。
> - **`wrapLanguageModel()`**：模型中间件——在 LLM 调用前后插入自定义逻辑（如消息格式转换）。
>
> Vercel AI SDK 的设计哲学是"一次编写，多 Provider 运行"——应用代码只与 SDK 的统一接口交互，切换 Provider 只需更换 SDK 包和配置。

OpenCode 选择 Vercel AI SDK 的理由包括：

1. **Provider 生态丰富**：官方和社区已为 20+ 个 Provider 提供了 `@ai-sdk/*` 包，每个包都实现了 `LanguageModelV2` 接口。
2. **流式原生**：`streamText()` 原生支持流式响应和工具调用，这对 CLI 的实时输出至关重要。
3. **类型安全**：完整的 TypeScript 类型定义，与 OpenCode 的 Zod-first 风格契合。
4. **中间件支持**：`wrapLanguageModel()` 允许在不修改 Provider SDK 的前提下注入自定义逻辑。
5. **活跃维护**：作为 Vercel 的核心开源项目，更新频率高，bug 修复快。

## 7.1.2 `LanguageModelV2` 接口的统一化

在 OpenCode 中，所有 Provider 最终都被归一化为 `LanguageModelV2` 接口：

```typescript
// 从 Vercel AI SDK 导入
import {
  streamText,
  wrapLanguageModel,
  type ModelMessage,
  type StreamTextResult,
  type Tool,
  type ToolSet,
  tool,
  jsonSchema,
} from "ai"
```

`LanguageModelV2` 是 Vercel AI SDK 定义的语言模型通用接口。无论底层是 Claude、GPT 还是 Gemini，上层代码都通过同一个接口进行调用。在 `LLM.stream()` 中，最终的调用是：

```typescript
return streamText({
  model: wrapLanguageModel({
    model: language,      // LanguageModelV2 实例
    middleware: [/* ... */],
  }),
  messages: [...],
  tools: {...},
  // ...
})
```

这种设计使得整个 Session、Agent、Tool 系统都不需要知道底层使用的是哪个 Provider——它们只与 `streamText()` 的统一接口交互。Provider 的差异被完全封装在 `provider/` 模块内部。

## 7.1.3 bundled Provider 与动态安装

OpenCode 内置了 20 个 Provider SDK：

```typescript
const BUNDLED_PROVIDERS: Record<string, (options: any) => SDK> = {
  "@ai-sdk/amazon-bedrock": createAmazonBedrock,
  "@ai-sdk/anthropic": createAnthropic,
  "@ai-sdk/azure": createAzure,
  "@ai-sdk/google": createGoogleGenerativeAI,
  "@ai-sdk/google-vertex": createVertex,
  "@ai-sdk/google-vertex/anthropic": createVertexAnthropic,
  "@ai-sdk/openai": createOpenAI,
  "@ai-sdk/openai-compatible": createOpenAICompatible,
  "@openrouter/ai-sdk-provider": createOpenRouter,
  "@ai-sdk/xai": createXai,
  "@ai-sdk/mistral": createMistral,
  "@ai-sdk/groq": createGroq,
  "@ai-sdk/deepinfra": createDeepInfra,
  "@ai-sdk/cerebras": createCerebras,
  "@ai-sdk/cohere": createCohere,
  "@ai-sdk/gateway": createGateway,
  "@ai-sdk/togetherai": createTogetherAI,
  "@ai-sdk/perplexity": createPerplexity,
  "@ai-sdk/vercel": createVercel,
  "@gitlab/gitlab-ai-provider": createGitLab,
  "@ai-sdk/github-copilot": createGitHubCopilotOpenAICompatible,
}
```

这些 Provider 被**静态导入并打包**（bundled），无需用户额外安装。每个 `create*` 函数接受配置选项并返回一个 `SDK`（即 `Provider`）实例。

对于不在 bundled 列表中的自定义 Provider，OpenCode 支持**运行时动态安装**：

```typescript
// getSDK() 中的动态安装逻辑
const bundledFn = BUNDLED_PROVIDERS[model.api.npm]
if (bundledFn) {
  // 使用内置的 Provider
  const loaded = bundledFn({ name: model.providerID, ...options })
  s.sdk.set(key, loaded)
  return loaded
}

// 动态安装自定义 Provider npm 包
let installedPath: string
if (!model.api.npm.startsWith("file://")) {
  installedPath = await BunProc.install(model.api.npm, "latest")
} else {
  installedPath = model.api.npm  // 本地文件协议
}

const mod = await import(installedPath)
const fn = mod[Object.keys(mod).find((key) => key.startsWith("create"))!]
const loaded = fn({ name: model.providerID, ...options })
```

动态安装流程：

1. 检查 npm 包名是否在 `BUNDLED_PROVIDERS` 中。
2. 如果不在，使用 `BunProc.install()` 在运行时安装该 npm 包。
3. 通过 `import()` 动态加载安装后的模块。
4. 通过命名约定（以 `create` 开头的导出函数）自动找到工厂函数。
5. 调用工厂函数创建 Provider 实例。

这种设计意味着用户可以使用**任何**实现了 Vercel AI SDK Provider 接口的 npm 包——即使 OpenCode 没有内置支持，也可以通过配置文件指定 npm 包名来使用。

---

下一节将深入分析 Provider 的注册与解析流程——从环境变量到配置文件，从 API Key 到 OAuth，OpenCode 如何将多来源的 Provider 信息统一管理。
