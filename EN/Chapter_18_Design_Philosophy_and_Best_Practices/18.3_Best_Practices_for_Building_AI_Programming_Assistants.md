# 18.3 Best Practices for Building AI Programming Assistants

> **Model**: claude-opus-4-6 (anthropic/claude-opus-4-6)
> **Generation Date**: 2026-02-18

---

In the previous two sections, we distilled design wisdom from the perspectives of OpenCode and oh-my-opencode respectively. This section integrates those experiences into an actionable **best practices guide** -- if you were to build an AI programming assistant from scratch, these are the principles most worth following.

## 18.3.1 Prompt Engineering Best Practices

### Layered Architecture for System Prompts

OpenCode's System Prompt is not a monolithic block -- it is assembled from multiple layers (Section 6.4.3):

```
Final System Prompt = [
  Base Prompt (anthropic.txt / beast.txt / ...)    <- Model adaptation layer
  + Agent-specific Prompt                            <- Agent role layer
  + Environment info (OS, Shell, working dir, Git status) <- Runtime context layer
  + Project instructions (AGENTS.md / CLAUDE.md / CONTEXT.md) <- User instruction layer
  + Plugin injection (experimental.chat.system.transform)  <- Extension layer
]
```

The benefits of this layered design:

| Layer | Change Frequency | Maintainer |
|-------|-----------------|------------|
| Model adaptation layer | Low (when new models are released) | OpenCode core developers |
| Agent role layer | Medium (when tuning Agent behavior) | Agent designers |
| Runtime context layer | Every session | System (automatic) |
| User instruction layer | Per project | Users / Teams |
| Extension layer | Per Plugin | Plugin developers |

**Practical Advice**: Split System Prompts into independently maintained layers. Each layer should have a clear responsibility and change frequency, avoiding one massive monolithic Prompt.

### Differentiated Adaptation by Model

Different LLMs have significantly different understanding of Prompts. OpenCode maintains independent base Prompts for each major model family:

- **Claude series** (`anthropic.txt`): Takes full advantage of XML tags for structuring instructions
- **GPT series** (`beast.txt`): Adapted to OpenAI's system message style
- **Gemini series** (`gemini.txt`): Adapted to the characteristics of Google's models
- **Other models** (`qwen.txt`): A streamlined generic version that removes features unsupported by certain models (such as the Todo tool)

**Practical Advice**: Do not assume one set of Prompts works for all models. At minimum, maintain different versions per model family, paying special attention to:
- Whether Tool Use / Function Calling is supported
- Differences in context window size
- Instruction-following style preferences (XML tags vs. Markdown vs. plain text)

### The Importance of Tool Descriptions

The LLM's choice of which tool to use and how to pass parameters **depends entirely on the tool's `description` field**. Every tool in OpenCode has a carefully written description text (stored in `.txt` files).

A good tool description should include:

```
1. What the tool does (one sentence)
2. When to use it (usage scenarios)
3. When NOT to use it (avoiding misuse)
4. Parameter descriptions (meaning and constraints of each parameter)
5. Output format (how the LLM should interpret the output)
```

Take OpenCode's `read` tool as an example: its description does not just say "reads a file." Instead, it provides detailed information about line number formatting, how image files are handled, PDF page limits, and other specifics. This information helps the LLM make correct decisions.

**Practical Advice**: Invest sufficient effort in writing tool descriptions. The quality of tool descriptions directly determines the behavioral quality of the AI Agent. A vague description will cause the LLM to frequently misuse the tool.

## 18.3.2 Security Best Practices

### Principle of Least Privilege

OpenCode's permission system (Chapter 9) follows a strict principle of least privilege:

```
Default behavior: All operations require user confirmation (ask)
    |
    v
Agent-level permissions: the build Agent allows most operations
    |
    v
User-level permissions: users can further loosen or tighten
    |
    v
Session-level permissions: temporary authorization at runtime
```

**Key Design Points**:
- **Bash commands** require permission matching based on command content (`bash("rm *")` is not the same as `bash("ls")`)
- **File writes** require permission matching based on path (writing to `src/` is not the same as writing to `/etc/`)
- **`.env` files** have special protection -- even if the Agent has read permission, reading `.env` requires additional confirmation
- **External directory** access has dedicated `external_directory` permission control

**Practical Advice**:
1. Deny all operations by default; open access on an as-needed basis
2. Add extra layers of protection for sensitive operations (file deletion, external access, key reading)
3. Distinguish between "one-time authorization" and "permanent authorization," giving users a choice
4. Log all permission decisions for auditing

### Sandboxing File Operations

OpenCode limits the AI's impact on the file system through these mechanisms:

| Protection Mechanism | Implementation | Protection Target |
|---------------------|----------------|-------------------|
| Project directory restriction | Tools default to operating only on files within the project directory | Prevent AI from modifying system files |
| `.gitignore` compliance | `file/ignore.ts` parses gitignore rules | Prevent AI from reading/modifying ignored files |
| External directory protection | `external_directory` permission | Prevent AI from accessing directories outside the project |
| Output truncation | `truncation.ts` limits tool output length | Prevent large file contents from flooding the context |

**Practical Advice**: Always assume the AI will attempt to do "unexpected" things. Establish multiple layers of defense so that even if one layer is bypassed, the others remain effective.

### Snapshots as a Safety Net

OpenCode's Snapshot system (Section 10.1) is the last line of defense:

```
Before file write -> Automatically create snapshot -> Write file
                                |
                                v
                          Problem found?
                                |
                                v
                          Restore snapshot -> File rollback
```

**Practical Advice**: Before the AI modifies any file, there should always be a rollback mechanism. The cost of Snapshots is extremely low (essentially `git add` + `git commit`), but the value is extremely high -- it gives users the confidence to let AI make large-scale code modifications.

## 18.3.3 Performance Optimization

### Context Window Management

The context window is an LLM's most precious resource. OpenCode manages it through a three-tier strategy (Section 4.5):

**Tier 1: Prune**

```
When context approaches the limit:
1. Start from the earliest messages
2. Find messages containing tool outputs
3. Truncate tool outputs to summaries
4. Protect the most recent PRUNE_PROTECT (40,000 tokens) of content from pruning
```

Pruning is "non-destructive" -- it only compresses tool outputs without deleting the messages themselves.

**Tier 2: Compaction**

```
When Pruning is insufficient:
1. Send all old messages to the LLM
2. Ask the LLM to generate a summary
3. Replace all old messages with the summary
```

Compaction is "lossy compression" -- details of old messages are lost, but key information is preserved through the summary.

**Tier 3: Preemptive Compaction (oh-my-opencode)**

```
Instead of waiting until overflow to compress, proactively trigger
when context utilization reaches a threshold.
This avoids the "overflow -> compress -> briefly usable -> overflow again" oscillation.
```

**Practical Advice**:
1. Tool outputs are the biggest consumers of context -- prioritize truncation and summarization of tool outputs
2. Implement progressive context management (Prune -> Compaction) rather than a single drastic truncation
3. Begin managing context before it approaches the limit, rather than waiting for overflow
4. Invest sufficient design effort in the Compaction summary Prompt -- the quality of the summary determines the quality of the AI's "memory" after compression

### Token-Saving Strategies

Every token has a cost. Here are token-saving practices from OpenCode and oh-my-opencode:

| Strategy | Implementation | Savings Effect |
|----------|---------------|----------------|
| Tool output truncation | `truncation.ts`, `tool-output-truncator` Hook | Prevent large files from consuming excessive tokens |
| Low-cost Agents first | oh-my-opencode's Explore Agent uses cheaper models | Search tasks completed with smaller models |
| Selective information injection | Inject context only in relevant scenarios | Avoid including large Prompt blocks with every message |
| Context isolation | Sub-Agents have independent contexts | Search results do not pollute the coding Agent's context |
| Precise search | Grep/Glob return only matching lines | Avoid reading entire files into context |

**Practical Advice**: Manage tokens like you manage memory. Every time you add content to the context, ask yourself: is this information truly necessary for the AI's next decision?

### Parallel Tool Execution

OpenCode's `batch` tool (Section 5.3.2) allows the AI to execute multiple independent tool calls simultaneously:

```typescript
// AI can read multiple files simultaneously rather than sequentially
batch({
  tasks: [
    { tool: "read", args: { file_path: "src/a.ts" } },
    { tool: "read", args: { file_path: "src/b.ts" } },
    { tool: "read", args: { file_path: "src/c.ts" } },
  ]
})
```

oh-my-opencode goes even further -- through its background Agent system (Section 15.6.1), it achieves Agent-level parallel execution.

**Practical Advice**: Identify operations that can be parallelized and provide the capability for parallel execution. This saves not only time but also tokens (by reducing the number of round-trip cycles "waiting for the previous step's result").

## 18.3.4 User Experience

### The Importance of Streaming Responses

AI response times can be long (seconds to tens of seconds). OpenCode uses streaming output to let users see that "the AI is thinking":

```
User: Help me refactor this function
AI: Let me first look at the implementation of this function...
    [Reading src/utils.ts...]             <- Real-time display of tool call status
    This function has the following issues:
    1. Excessive nesting...                <- Text appears token by token
    2. Redundant error handling...
```

**Key Experience Details**:
- Text is streamed token by token (`text-delta` events)
- Tool call progress is visible (`tool-call-start` -> `running` -> `completed`)
- The chain of thought is visible (`reasoning-start` -> `reasoning-delta` -> `reasoning-end`)

**Practical Advice**: Never leave the user facing a "blank wait." Even if you only display a "Thinking..." spinner animation, it is better than nothing. Streaming output is one of the most important UX features of AI products.

### Progress Visibility

When AI performs complex tasks, users need to know "what it is doing and how far along it is":

| Mechanism | Implementation | Purpose |
|-----------|---------------|---------|
| Todo list | `TodoWriteTool` + `TodoReadTool` | AI creates its own task checklist and completes items one by one |
| Tool call display | TUI shows the name and status of each tool call | Users can track AI operations in real time |
| Session summary | `SessionSummary` tracks file modifications | Users know which files the AI modified |
| Diff display | Snapshot diff | Precisely shows changes in each file |

**Practical Advice**: Make the AI's work process transparent and visible. User trust in AI comes from "I can see what it is doing," not from "I trust it will get it right."

### Transparency in Error Recovery

When the AI makes a mistake (such as a failed edit), the system should:

```
Bad handling:
  "Error: old_string not found" (directly exposing the raw error)

Good handling (oh-my-opencode's edit-error-recovery):
  "Edit failed: the target string does not exist in the file.
   Possible cause: the file content has changed.
   Suggestion: re-read the file first, then try editing again."
```

oh-my-opencode's error recovery Hooks do not just catch errors -- they also **inject repair suggestions for the AI**, enabling the AI to attempt fixes autonomously.

**Practical Advice**:
1. Transform raw errors into guidance that the AI can understand
2. Provide specific fix suggestions rather than abstract error codes
3. Give the AI the opportunity to attempt fixes autonomously, rather than interrupting the user every time

---

The common theme across these best practices is: **respect AI's non-determinism while maximizing its value**. A good AI programming assistant is not an "infallible super-programmer" -- it is a "programming partner that occasionally needs correction but is efficient and reliable overall." The goal of system design is to enable the AI to recover quickly when it makes mistakes and perform fully when it is correct.
