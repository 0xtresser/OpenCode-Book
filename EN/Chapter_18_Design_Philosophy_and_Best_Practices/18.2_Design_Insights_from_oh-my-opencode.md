# 18.2 Design Insights from oh-my-opencode

> **Model**: claude-opus-4-6 (anthropic/claude-opus-4-6)
> **Generation Date**: 2026-02-18

---

If OpenCode demonstrates "how to build an extensible AI programming assistant engine," then oh-my-opencode demonstrates "how to build a powerful AI programming team on top of that engine." As the most complex third-party Plugin in the OpenCode ecosystem, the design philosophy of oh-my-opencode is worth studying for every AI application developer.

## 18.2.1 "Prompt Engineering as Code" -- Making Prompt Engineering Systematic

In many AI applications, Prompts exist as "configuration" or "string constants" -- written in configuration files or databases, manually adjusted by humans. oh-my-opencode takes a completely different approach: **treating Prompts as code to be engineered systematically**.

### Dynamic Prompt Builder

One of oh-my-opencode's core innovations is `dynamic-agent-prompt-builder.ts` -- a system that dynamically generates Prompts based on runtime state:

```typescript
// Not hardcoded strings, but dynamically built based on available Agents
export function buildToolSelectionTable(
  agents: AvailableAgent[],
  tools: AvailableTool[],
): string {
  const rows: string[] = ["### Tool & Agent Selection:", ""]

  // Generate table based on actually available tools
  if (tools.length > 0) {
    rows.push(`- ${formatToolsForPrompt(tools)} — **FREE** — Not Complex`)
  }

  // Sort Agents by cost, lowest first
  const sorted = [...agents].sort(
    (a, b) => costOrder[a.metadata.cost] - costOrder[b.metadata.cost]
  )
  for (const agent of sorted) {
    rows.push(`- \`${agent.name}\` — **${agent.metadata.cost}** — ${agent.description}`)
  }

  return rows.join("\n")
}
```

This means:

- **Prompts change as configuration changes**: If a user disables an Agent, the Prompt will not contain any reference to it
- **Prompts stay in sync with data**: There will never be a situation where a Prompt mentions a tool that does not exist
- **Prompts can be tested**: The builder functions are pure functions that can be verified with unit tests

### Version-Controlled Prompts

In oh-my-opencode, each Agent's Prompt is a standalone TypeScript file (e.g., `agents/sisyphus.ts`, `agents/oracle.ts`) rather than a `.txt` text file. This allows Prompts to:

- Reference variables and constants
- Use template string interpolation
- Include conditional logic
- Benefit from TypeScript's type checking

```typescript
// Prompt snippet from agents/sisyphus.ts
const systemPrompt = `You are Sisyphus -- the technical lead of ${teamDescription}.

## Available Team Members
${buildDelegationTable(availableAgents)}

## Current Project Context
${envContext}

## Delegation Protocol
${delegationProtocol}
`
```

### Design Insight

**Treat Prompts as code, not configuration** -- this means Prompts should enjoy all the engineering practices of code: version control, code review, unit testing, and dynamic assembly. For complex AI applications, static Prompt strings are insufficient.

## 18.2.2 "Hooks as Strategies" -- The Design Philosophy Behind 53 Hooks

oh-my-opencode registers as many as 53 Hooks (Section 15.5), covering everything from message handling to error recovery. But what matters is not the quantity -- it is the underlying **design philosophy**.

### Hooks as a Strategy Pattern

The traditional Strategy Pattern is typically implemented with Classes and interfaces. oh-my-opencode uses Hooks to implement a more flexible variant of the Strategy Pattern:

```
+------------------------------------------+
|            OpenCode Core                  |
|                                          |
|  Send message --Hook--> chat.message     |
|  Before tool exec --Hook--> tool.execute.before |
|  After tool exec --Hook--> tool.execute.after   |
|  Session compaction --Hook--> session.compacting |
|                                          |
+------------------------------------------+
          |
          v
+------------------------------------------+
|       oh-my-opencode Strategy Layer       |
|                                          |
|  chat.message:                           |
|    +-- stop-continuation-guard  <- Prevent infinite loops   |
|    +-- keyword-detector         <- Keyword detection        |
|    +-- auto-slash-command       <- Automatic commands       |
|    +-- agent-usage-reminder     <- Agent usage reminders    |
|                                          |
|  tool.execute.after:                     |
|    +-- tool-output-truncator    <- Output truncation        |
|    +-- preemptive-compaction    <- Preemptive compaction    |
|    +-- comment-checker          <- Comment checking         |
|                                          |
+------------------------------------------+
```

Each Hook is an independent **strategy** that can be enabled or disabled via configuration:

```json
{
  "disabled_hooks": ["ralph-loop", "auto-slash-command"]
}
```

### Hook Classification System

The 53 Hooks are not added arbitrarily -- they form a clear classification system:

| Category | Representative Hooks | Design Intent |
|----------|---------------------|---------------|
| **Error Recovery** | `edit-error-recovery`, `session-recovery`, `json-error-recovery` | AI makes mistakes; the system should auto-repair |
| **Context Management** | `preemptive-compaction`, `context-window-monitor` | Tokens are a scarce resource that must be proactively managed |
| **Behavior Constraints** | `stop-continuation-guard`, `unstable-agent-babysitter` | AI needs "guardrails" to prevent runaway behavior |
| **Information Injection** | `directory-agents-injector`, `rules-injector` | Provide AI with the context it needs for decision-making |
| **Output Control** | `tool-output-truncator`, `thinking-block-validator` | Control the quality and format of AI output |
| **Task Management** | `todo-continuation-enforcer`, `task-reminder` | Ensure AI completes all subtasks |

### Design Insight

**Do not try to make AI get it right on the first attempt -- instead, build multiple layers of safety nets**. oh-my-opencode's 53 Hooks form a "Defense in Depth" system:

1. **Prevention Layer**: `stop-continuation-guard` prevents infinite AI loops
2. **Detection Layer**: `context-window-monitor` monitors context window utilization
3. **Repair Layer**: `edit-error-recovery` automatically fixes failed edits
4. **Fallback Layer**: `session-recovery` attempts recovery when a session crashes

Each layer assumes the layer above it may fail. This **defensive design** is key to building reliable AI systems.

## 18.2.3 "Agent Personification" -- From Greek Mythology to Engineering Practice

oh-my-opencode gives its Agents names from Greek mythology: Sisyphus, Oracle, Prometheus, Hephaestus, Atlas, Metis, Momus...

This is not merely a naming preference -- it reflects a carefully considered **Agent design methodology**.

### Names Imply Roles

Each mythological figure's story creates an association with the Agent's function:

| Agent Name | Mythological Background | Functional Association |
|------------|------------------------|----------------------|
| **Sisyphus** | Condemned to forever roll a boulder uphill | Main Agent, repeatedly handles tasks, never gives up |
| **Oracle** | The Oracle of Delphi, foresees the future | Technical advisor, provides decision-making counsel |
| **Prometheus** | The foresighted one who stole fire for humanity | Task planner, brings the "spark" (a plan) |
| **Hephaestus** | The craftsman god of Olympus | Code craftsman, focused on implementation |
| **Explore** | -- | Code search expert (retains a pragmatic name) |
| **Metis** | Goddess of wisdom, counselor to Zeus | Pre-planning analyst |
| **Momus** | God of criticism, finds fault in everything | Solution review expert |
| **Atlas** | The Titan who holds up the sky | Project navigator, carries global information |

The benefits of this naming strategy:

**1. Memorability**

Compare these two log excerpts:
```
[sisyphus] Delegating to prometheus for planning
[prometheus] Planning complete, handing off to hephaestus for implementation
```
vs.
```
[agent-001] Delegating to agent-003 for planning
[agent-003] Planning complete, handing off to agent-004 for implementation
```

Mythological names make multi-Agent collaboration logs read like a "story," greatly improving comprehensibility.

**2. Mental Model Anchoring**

When you know Sisyphus is "the man who forever pushes the boulder," you intuitively understand that it is an Agent that **never gives up and keeps trying**. This mental model helps developers quickly grasp an Agent's behavioral characteristics.

**3. Prompt Engineering Anchors**

Agent names can be used directly in Prompts to reinforce role identity:

```
You are Sisyphus -- a technical lead who never gives up.
No matter how difficult the task, you will find a way to complete it.
```

### Design Insight

**Give Agents meaningful "personalities."** This is not superfluous ornamentation -- it helps developers understand the Agent's design intent, helps the LLM better "get into character," and makes the system's behavior more predictable. Good Agent names should:

- Imply their core responsibility
- Make it obvious at a glance "what they are good at"
- Be easily distinguishable in logs and debugging

## 18.2.4 "Defensive Programming" -- Error Recovery and Fallback Strategies

The fundamental difference between AI systems and traditional software is: **LLM output is non-deterministic**. Traditional software has bugs because the code is wrong, but an AI system "has bugs" simply because the model "thought differently this time."

oh-my-opencode deeply understands this and has built a comprehensive **defensive programming** framework.

### Error Classification and Targeted Recovery

The `session-recovery` Hook is a prime example. Rather than simply `try-catch` and report an error, it **classifies errors and prescribes specific remedies**:

```typescript
export type RecoveryErrorType =
  | "tool_result_missing"          // Tool result missing
  | "thinking_block_order"         // Thinking block order error
  | "thinking_disabled_violation"  // Thinking blocks appeared when thinking is disabled
  | "assistant_prefill_unsupported" // Assistant prefill not supported

export function detectErrorType(error: unknown): RecoveryErrorType {
  const message = getErrorMessage(error)

  if (message.includes("tool_use") && message.includes("tool_result")) {
    return "tool_result_missing"
  }
  if (message.includes("thinking") && message.includes("first block")) {
    return "thinking_block_order"
  }
  // ...
}
```

Each error type has a dedicated recovery strategy:

| Error Type | Recovery Strategy |
|-----------|------------------|
| `tool_result_missing` | Supplement the missing tool result and resubmit |
| `thinking_block_order` | Reorder thinking blocks in the message |
| `thinking_disabled_violation` | Remove thinking content from the message |
| `assistant_prefill_unsupported` | Convert assistant messages to user messages |

### Multi-Layer Fault Tolerance Design

oh-my-opencode's fault tolerance is not single-point -- it is **multi-layered and nested**:

```
Layer 1: edit-error-recovery
  When the edit tool fails (e.g., old_string is not unique),
  automatically provide fix suggestions rather than letting the Agent retry blindly

Layer 2: unstable-agent-babysitter
  Monitor sub-Agent behavior; if abnormal output is detected
  (e.g., consecutive failures, excessively short output), intervene automatically

Layer 3: session-recovery
  If the entire session crashes due to an API error,
  analyze the error type, attempt to fix messages, and recover

Layer 4: context-window-monitor + preemptive-compaction
  Proactively compress before the context window approaches its limit,
  avoiding hard errors caused by exceeding the limit
```

### Design Insight

When building AI systems, follow these **defensive programming principles**:

1. **Error classification over generic catch**: Different types of errors require different recovery strategies
2. **Proactive prevention over reactive repair**: `preemptive-compaction` acts before overflow occurs
3. **Graceful degradation over total failure**: Even if one Agent fails, the system should continue running
4. **All external interactions can fail**: LLM API calls, tool execution, file operations -- every step should have fault-tolerant handling
5. **Log the recovery process**: Logs of error recovery are crucial for debugging and improvement

---

These four design insights from oh-my-opencode -- Prompt engineering as code, the Hook strategy system, Agent personification, and defensive programming -- apply not only to OpenCode Plugin development but also represent universal design wisdom for all AI Agent systems. In the next section, we will integrate these insights with OpenCode core's design decisions to distill best practices for building AI programming assistants.
